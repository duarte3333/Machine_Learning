# Machine Learning Project
## Introduction

This machine learning project had four parts – two were about predicting values (regression), and the other two 
were about sorting things into categories (classification). It's a type of learning(Supervised Learning) where the computer learns from both input and output data to get better at the task.

<p align="center">
  <img src="https://github.com/duarte3333/Machine_Learning/assets/76222459/03de7155-5f1a-433c-b459-4b28a41459e6" alt="image" width="400" />
</p>

### Regression:

Regression in machine learning involves the prediction of continuous numerical values based on input data. The goal of regression is 
to model the relationship between input features and a continuous output, allowing for accurate predictions. For example, 
regression can be applied to tasks such as predicting house prices, stock prices, or temperature, where the algorithm 
learns patterns from historical data to make predictions about new, unseen data points.

### Classification:

Classification in machine learning involves predicting the category or class to which an input belongs. The goal of 
classification is to build a model that can accurately assign input instances to predefined categories. For instance, 
classification is widely used in various applications, including spam detection in emails, image recognition tasks, sentiment 
analysis in natural language processing, and medical diagnosis, where diseases are categorized based on patient data. 
The algorithm learns from labeled data to classify new, unseen instances into distinct predefined classes.

### Goal of Machine Learning:

Machine learning aims to create algorithms that autonomously learn patterns from data for making predictions or decisions. The focus is 
on developing models that generalize effectively to new, unseen data. Regression and classification are specific tasks within the 
broader goal of machine learning, demonstrating its versatile applications in predicting continuous values and categorizing inputs into predefined classes.

## 1. Regression

### 1.1 First Task

**Goal:** The goal was to make predictions based on a dataset with 15 examples and 10 features, evaluating seven regression models.

**Models Used:**
- Linear Regression
- Ridge Regression
- Lasso Regression
- Lasso LARS
- Elastic Net
- Orthogonal Matching Pursuit (OMP)

**Approach:** Ten-fold cross-validation with Mean Squared Error (MSE) metric.

**Results and Conclusions:**
<p align="center">
  <img src="https://github.com/duarte3333/Machine_Learning/assets/76222459/66422e86-e573-4bde-a977-f11c2234b337" alt="image" />
</p>

- OMP model performed the best with the lowest MSE (2.680).
- OMP identified five non-zero coefficients, emphasizing its significance in feature selection.
- Lasso Regression performed less effectively than Ridge Regression.
- Data normalization was deemed unnecessary based on histogram visualization.

### 1.2 Second Task

**Goal:** Make predictions using a dataset generated by two different linear models with 100 examples and four features. Distinguish between instances created by these two distinct models.

**Models Used:**
- K-Means
- Gaussian Mixture Model (GMM)
<p align="center">
  <img src="https://github.com/duarte3333/Machine_Learning/assets/76222459/03f1a71f-bf3b-4023-a555-fb7c59def432" alt="image" />
</p>

**Approach:** Applied clustering techniques (K-Means and Gaussian Mixture Model) to divide the 
training data and create individual regression models.

**Results and Conclusions:**
<p align="center">
  <img src="https://github.com/duarte3333/Machine_Learning/assets/76222459/8a72a055-ad29-43f6-a870-e15f735d8871" alt="image" width="700" />
</p>

- Gaussian Mixture Model with Ridge Regression achieved the lowest MSE (0.046).
- Residual analysis and input training data approach explored.
- Importance of considering both input and output data for clustering.

## 2. Classification

### 2.1 First Task

**Goal:** Perform binary image classification on dermoscopy images, predicting whether an image is from a melanoma or a nevus.

<p align="center">
  <img src="https://github.com/duarte3333/Machine_Learning/assets/76222459/51f06b36-db81-42c4-98d4-9d093fa429f1" alt="image" width="700" />
</p>

**Data Preparation:**
- Normalization of input vectors.
- Transformation of y vector into one-hot encoding.
- Shuffling and splitting of training data.

**Models Used:**
- Convolutional Neural Network (CNN)
- Support Vector Machine (SVM)

**Approach:**
- Evaluation metric: Balanced Accuracy.
- CNN architectures with data augmentation, class weights, and oversampling.
- SVM with kernel: RBF, Poly, Linear.

**Results and Conclusions:**
- CNN number 3 with balanced data augmentation performed the best.
- Challenges with overfitting and class imbalance observed.
- Poor performance of SVM compared to CNN.

**Summary of the Results:**
<p align="center">
  <img src="https://github.com/duarte3333/Machine_Learning/assets/76222459/df365e89-3ee1-457f-b4ce-be0c912f2e2d" alt="image" width="800" />
</p>

**Confusion Matrix for CNN the best results (CNN3) using Validation Data:**
<p align="center">
  <img src="https://github.com/duarte3333/Machine_Learning/assets/76222459/1e5b33f7-055d-4151-a0f7-4ebdc5c949a7" alt="image" width="500" />
</p>

**Insights:**
- Overfitting observed in CNN architecture.
- F1 score and confusion matrix crucial for evaluation.
- Consideration of data imbalance in CNN essential.

### 2.2 Second Task

**Goal:** The second part of the classification project focused on classifying 2D medical images from two 
distinct datasets: dermoscopy and blood cell microscopy. The objective was to classify these images 
into six different categories: nevus (0), melanoma (1), vascular lesions (2), granulocytes (3), basophils (4), and lymphocytes (5).

<p align="center">
  <img src="https://github.com/duarte3333/Machine_Learning/assets/76222459/eb36243c-94f5-4f8a-8250-f107e182625d" alt="image" />
</p>

**Models Used**
- Convolutional Neural Network (CNN)
<p align="center">
  <img src="https://github.com/duarte3333/Machine_Learning/assets/76222459/d64a9b4c-1aa0-4949-9838-4158adf7a56c" alt="image" width="500" />
</p>

**Data Preprocessing**
- Random oversampling technique employed for minority classes to address class imbalance.
- Data augmentation techniques applied to increase model diversity and robustness.

**Results and Conclusions**
- Two CNN models (Model 1 and Model 2) were evaluated using different approaches.
- Evaluation metrics: Balanced Accuracy, F1 Score (for each class).
- Random oversampling achieved the best results for both models, outperforming data augmentation and class weights approaches.
- Model 2 consistently outperformed Model 1 in terms of Balanced Accuracy and F1 Score for each class.

**Summary of Approaches and Results for CNN number 1:**

<p align="center">
  <img src="https://github.com/duarte3333/Machine_Learning/assets/76222459/69343c0d-3cdb-41da-a342-e433ab9e30d6" alt="image" />
</p>

**Summary of Approaches and Results for CNN number 2:**

<p align="center">
  <img src="https://github.com/duarte3333/Machine_Learning/assets/76222459/bc86fd66-cb63-40e2-a077-4ffa0dfc5775" alt="image" />
</p>

**Confusion Matrix for CNN with best results (CNN2) using Validation Data:**

<p align="center">
  <img src="https://github.com/duarte3333/Machine_Learning/assets/76222459/217d823f-bd20-4fb2-91f0-e090d504369a" alt="image" width="600" />
</p>

**Insights:**

- Random oversampling proved effective in addressing class imbalance.
- Model 2 consistently outperformed Model 1, indicating the importance of the chosen approach.
- F1 Score and confusion matrix provided detailed insights into model performance.

## Authors
- Duarte Sá Morais (100163) - [duarte.morais@tecnico.ulisboa.pt](mailto:duarte.morais@tecnico.ulisboa.pt)
- João Dias (100202) - [joao.v.dias@tecnico.ulisboa.pt](mailto:joao.v.dias@tecnico.ulisboa.pt)

